## ðŸ“– Project Overview

In this project, users upload a video file, and the app first extracts and transcribes the audio using OpenAIâ€™s Whisper model. The raw transcription is then corrected using a T5-based grammar correction model to improve grammar, spelling, and fluency, while also highlighting the changes compared to the original text. A 5-second audio clip from the uploaded video is trimmed to serve as a voice reference. Using the XTTS-v2 model from Coqui, the app performs voice cloning to synthesize the corrected text into natural-sounding speech that matches the original speakerâ€™s voice. Finally, the generated voice audio is made available for playback directly within the app, completing an end-to-end process of transcription, grammar enhancement, and speaker-adapted text-to-speech synthesis.

---

## ðŸ“‚ Project Structure

. â”œâ”€â”€ Assets_Text.py â”œâ”€â”€ requirements.txt â”œâ”€â”€ Streamlit_App.py â”œâ”€â”€ saved_output/ â”‚ â”œâ”€â”€ extracted_audio_segments/ â”‚ â”œâ”€â”€ transcribed_subtitles.srt â”‚ â”œâ”€â”€ incorrect_paragraph.txt â”‚ â”œâ”€â”€ corrected_paragraph.txt â”‚ â”œâ”€â”€ full_audio.wav â”‚ â”œâ”€â”€ trimmed_ref.wav â”‚ â””â”€â”€ output.wav â””â”€â”€ .env
