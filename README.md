This repository provides a Streamlit-based pipeline that—from a video file—automatically transcribes speech using OpenAI’s Whisper model (with GPU support), formats the transcript into SRT subtitles, extracts per-line audio segments (and the full audio track) via pydub, runs each subtitle line through a T5-based grammar-correction model hosted on Hugging Face (authenticated via an HF_TOKEN), cleans up any stray tokens, and then optionally highlights word-level edits in HTML or generates new speech audio using Microsoft Edge’s neural voices via the edge-tts async API—all while organizing inputs and outputs under a saved_output/ directory.
