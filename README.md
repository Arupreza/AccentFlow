## ðŸ“– Project Overview

In this project presents a turnkey Streamlit web application that exposes the entire speechâ€‘processing and reâ€‘synchronisation stackâ€”audio extraction, chunking, automatic speech recognition (ASR), grammatical error correction (GEC), crossâ€‘lingual textâ€‘toâ€‘speech (TTS), and automatic lipâ€‘sync regenerationâ€”through a single interactive dashboard. Users can upload any video, adjust segment duration, provide an optional Hugging Face token, monitor colourâ€‘coded progress bars and live logs, and download every intermediate artefact: the full WAV track, perâ€‘segment clips, SRT subtitles, raw and corrected transcripts, clonedâ€‘voice WAV output, and the final lipâ€‘synced MP4. Under the hood the app orchestrates Pydub for audio handling, OpenAI Whisperâ€‘medium for ASR, a fineâ€‘tuned T5â€‘base GEC model, and Coqui XTTSâ€‘v2 for zeroâ€‘shot speaker cloning, with all models cached by Streamlitâ€™s resource manager and GPUâ€‘accelerated when available. Once the corrected speech is synthesised, ByteDance LatentSyncâ€‘1.5 reâ€‘aligns the speakerâ€™s mouth movements in the original video to the updated audio track, producing frameâ€‘accurate lipâ€‘sync.

<!-- Image goes here -->
<img src="Assets/Diagram.png" width="800">

<img src="Assets/Page_1.png" width="800">
<img src="Assets/Page_2.png" width="800">
<img src="Assets/Page_3.png" width="800">
<img src="Assets/Page_4.png" width="800">

## Output WAV Sample

<audio src="Assets/generated_speech.wav" controls></audio>

Python: 3.10
##
CUDA: conda install pytorch==2.1.0 torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
---
